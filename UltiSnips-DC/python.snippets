priority -50

###########################################################################
#                            TEXTMATE SNIPPETS                            #
###########################################################################

snippet classInit "init class with parameter" b
# class definition
class ${1:Myclass}:
    # define property
    ${2:name}= ''
    ${3:age}= 0
	# define private property, could not access outside
    __${4:weight}= 0
    # define construction
    def __init__(self,n,a,w):
        self.$2= n
        self.$3= a
        self.__$4 = w
    def speak(self):
        print("%s say: i am %d old" %(self.$2,self.$3))

# new instantiate 
p = $1('runoob',10,30)
p.speak()
$0
endsnippet

snippet withopen "with open system argv[1]" b
with open(sys.argv[1],'r',encoding='utf-8-sig') as f:
	all_line_list = f.readlines()
$0
endsnippet

snippet readFileChunks "read file by chunks" b
def read_in_chunks ( filePath , chunk_size = 1024*1024):
    """
    Lazy function (generator) to read a file piece by piece.
    Default chunk size: 1M
    You can set your own chunk size
    """
    file_object = open (filePath)
    while True :
        chunk_data = file_object.read(chunk_size)
        if not chunk_data :
        break
        yield chunk_data


for chunk in read_in_chunks('/path/to/file'):
    process (chunk)
$0
endsnippet

snippet translatePyScript "translate python script" b
from urllib import request, parse
import json
import sys
def fanyi(content):
    req_url = 'http://fanyi.youdao.com/translate'
    head_data = {}
    head_data['Referer'] = 'http://fanyi.youdao.com/'
    head_data['User-Agent'] = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36X-Requested-With: XMLHttpRequest'
    form_data = {}
    form_data['i'] = content
    form_data['doctype'] = 'json'
    data = parse.urlencode(form_data).encode('utf-8')
    req = request.Request(req_url, data, head_data)
    response = request.urlopen(req)
    html = response.read().decode('utf-8')
    translate_results = json.loads(html)
    translate_results = translate_results['translateResult'][0][0]['tgt']
    # print(translate_results)
    return translate_results
 
if __name__ == '__main__':
    with open(sys.argv[1], "r") as f: #.txt的位置
        lines = f.readlines()
    for line in lines:
        eng=fanyi(line)
        print(eng)
    f.close()
$0
endsnippet


snippet printWords2Cloud "print words files to cloud" b
#pip install jieba
#pip install wordcloud
#pip install scipy
#pip install matplotlib
import sys
import jieba
from wordcloud import WordCloud,ImageColorGenerator
import matplotlib.pyplot as plt
from scipy.misc import imread

print("word file name:",sys.argv[2])
data = open(sys.argv[1],"r",encoding='utf-8').read()
cutData = jieba.cut(data, cut_all=True)
# jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型。
word = " ".join(cutData)#把分词链接起来，加空格因为英文靠空格分词

print("picture file name:",sys.argv[1])
bg_pic = imread(sys.argv[2])#读取图片
wordcloud = WordCloud(mask=bg_pic,background_color='white',font_path="/home/dc/.local/share/fonts/微软雅黑Bold.ttf",max_words=1000,max_font_size=150,scale=1).generate(word)
image_colors = ImageColorGenerator(bg_pic)#从背景图片生成颜色值
plt.imshow(wordcloud)#使图片颜色跟字体颜色一样，合并一起

plt.axis("off")#关闭显示坐标
#plt.show()
wordcloud.to_file(sys.argv[3])#保存到文件
$0
endsnippet

snippet decoratorFormwork "decorator Formwork" b
def decorator(para):
    """TODO: Docstring for decorator.
    :arg1: TODO
    :returns: TODO
    """
	def function(func):
		"""TODO: Docstring for decorator.
		:arg1: TODO
		:returns: TODO
		"""
		def wraper( *args, **kwargs,):
			"""TODO: Docstring for wraper.
			:returns: TODO
			"""
			print("start...")
			func( *args, **kwargs,)
			print("end...")
		return wraper
	return function


def function():
    print('function runing')

function= decorator("para1")(decorator("para2")(function))
function()

$0
endsnippet

snippet iteratorFormwork "iterator Formwork" b
#!/usr/bin/env python
# coding=utf-8
class Fib:

    """Docstring for Fib. """

    def __init__(self,n):
        """TODO: to be defined. """
        self.prev = 0
        self.cur = 1
        self.n = n
    def __iter__(self):
        return self

    def __next__(self):
        if self.n > 0:
           self.prev, self.cur = self.cur, self.cur + self.prev
           self.n -= 1
           return self.cur
        else:
            raise StopIteration()

myclass = Fib(10)
myiter = iter(myclass)
for x in myiter:
	print(x)

$0
endsnippet

snippet generatorFormwork "Generator Formwork" b
#!/usr/bin/env python
# coding=utf-8
import sys
def fibonacci(n): 
    """TODO: Docstring for fibonacci.

    :arg1: TODO
    :returns: TODO

    """
    a, b, counter = 0, 1, 0
    while True:
        if (counter > n):
            return
        yield a
        a, b = b, a + b
        counter += 1

f = fibonacci(10) # f is a iterater
while True:
    try:
        print(next(f), end=" ")
    except StopIteration:
        sys.exit()
$0
endsnippet

snippet mapFormwork "map Python" b
def f(x):
    return x * x
r = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])
$0
endsnippet

snippet reduceFormwork "reduce Python" b
# reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)
from functools import reduce
def add(x, y):
    return x + y
reduce(add, [1, 3, 5, 7, 9])
$0
endsnippet


snippet filterFormwork "filter Python" b
def is_odd(n):
    return n % 2 == 1

list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))
$0
endsnippet

snippet sortFormwork "sort Python" b
L = [('Bob', 75), ('Adam', 92), ('Bart', 66), ('Lisa', 88)]
def by_name(t):
    pass

L2 = sorted(L, key=by_name)
print(L2)


from operator import itemgetter

L = ['bob', 'about', 'Zoo', 'Credit']

print(sorted(L))
print(sorted(L, key=str.lower))

students = [('Bob', 75), ('Adam', 92), ('Bart', 66), ('Lisa', 88)]

print(sorted(students, key=itemgetter(0)))
print(sorted(students, key=lambda t: t[1]))
print(sorted(students, key=itemgetter(1), reverse=True))
$0
endsnippet

snippet lambdaFormwork "lambda Formwork" b
list(map(lambda x: x * x, [1, 2, 3, 4, 5, 6, 7, 8, 9]))
$0
endsnippet

snippet listComprehensions "list Comprehensions" b
${1:list_result} = [${2:item} for $2 in ${3:array} if $2 == 'a']
$0
endsnippet

snippet multipleprocess "multiple process " b
def run_proc(name):
    print('Run child process %s (%s)...' % (name, os.getpid()))

print('Parent process %s.' % os.getpid())
p = Process(target=run_proc, args=('test',))
print('Child process will start.')
p.start()
p.join()
print('Child process end.')
$0
endsnippet

snippet multipleThread "multiple Thread" b
def run_proc(name):
	print('Run child process %s (%s)...' % (name, os.getpid()))

print('Parent process %s.' % os.getpid())
p = Process(target=run_proc, args=('test',))
print('Child process will start.')
p.start()
p.join()
print('Child process end.')
endsnippet

snippet wordCloud2Img "snip Test Python" b
import sys
import jieba
from wordcloud import WordCloud,ImageColorGenerator
import matplotlib.pyplot as plt
from scipy.misc import imread

print("word file name:",sys.argv[2])
data = open(sys.argv[1],"r",encoding='utf-8').read()
cutData = jieba.cut(data, cut_all=True)
# jieba.cut 方法接受三个输入参数: 需要分词的字符串；cut_all 参数用来控制是否采用全模式；HMM 参数用来控制是否使用 HMM 模型。
word = " ".join(cutData)#把分词链接起来，加空格因为英文靠空格分词

print("picture file name:",sys.argv[1])
bg_pic = imread(sys.argv[2])#读取图片
wordcloud = WordCloud(mask=bg_pic,background_color='white',font_path="/home/dc/.local/share/fonts/微软雅黑Bold.ttf",max_words=1000,max_font_size=150,scale=1).generate(word)
image_colors = ImageColorGenerator(bg_pic)#从背景图片生成颜色值
plt.imshow(wordcloud)#使图片颜色跟字体颜色一样，合并一起

plt.axis("off")#关闭显示坐标
#plt.show()
wordcloud.to_file(sys.argv[3])#保存到文件
$0
endsnippet

snippet snipTestPython "snip Test Python" b
snip Test Python
$0
endsnippet
# vim:ft=snippets:
